{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relatório"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CEFET-MG  \n",
    "Recuperação da Informação\n",
    "\n",
    "Trabalho Prático 1  \n",
    "Professor: Daniel Hasan    \n",
    "Arthur de Morais Novaes\n",
    "\n",
    "Descritor do Coletor:  [https://armonovabot.wordpress.com/](https://armonovabot.wordpress.com/)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principais desafios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um dos maiores desafios, sem dúvidas, foi trabalhar com threads. Uma vez que a paralização de um código exige diversos cuidados, como por exemplo a gestão de variáveis que são utilizadas por todas as threads, além disso é necessário também um conhecimendo sobre python para a utilização de comandos da própria linguágem para auxiliar nesse gerenciamento das threads. E essa questão introduz o segundo grande desafio, que foi ter que aprender o básico sobre a linguagem utilizada, uma vez que o coletor não é um código simples e para a implementação de toda a lógica foi necessário um conhecimento um pouco aprofundado de Python. Isso com certeza teve um peso muito consideravem no tempo total de desenvolvimento do trabalho.\n",
    "\n",
    "Como já dito acima, a linguagem escolhida foi o Python3 por ser uma linguagem com uma curva de aprendizado menor, uma vez que é uma linguagem bem simples, porém extremamente poderosa. Além disso os testes unitários foram feitos no Jupyter Notebook e o código foi escrito e testado na IDA Pycharm da JetBrains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URLs sementes utilizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foram utilizadas 30 sementes, sendo elas:  \"https://www.uol.com.br/\",\"https://www.globo.com/\",\"https://www.terra.com.br/\",\"https://www.msn.com/pt-br\",\"https://www.techtudo.com.br/\",\"https://canaltech.com.br/\",\"https://github.com/\",\"https://docs.python.org/3/\",\"https://pt.wix.com/\",\"https://br.wordpress.com/\",\"https://www.pathofexile.com/\",\"https://www.reddit.com\",\"https://www.r7.com/\",\"https://www.twitch.tv\",\"https://www.estadao.com.br/\",\"https://www.ig.com.br/\",\"https://www.portaldoholanda.com.br/\",\"https://www.gazetadopovo.com.br/\",\"https://www.naosalvo.com.br/\",\"https://www.Facebook.com\",\"https://www.Baidu.com\",\"https://www.Wikipedia.org\",\"https://www.Yahoo.com\",\"https://www.Qq.com\",\"https://www.Taobao.com\",\"https://www.Twitter.com\",\"https://www.Amazon.com\",\"https://www.Google.co.jp\",\"https://www.Tmall.com\",\"https://www.Vk.com\","
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como foi feito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi criada 3 classes em Python, abaixo temos uma breve explicação de cada método em cada classe\n",
    "- Classe Domain:\n",
    "    - `time_since_last_access`: tempo entre o último acesso e o tempo atual\n",
    "    - `accessed_now`: armazena na variável `time_last_access` o tempo do último acesso daquele domínio.\n",
    "    - `is_accessible`: verifica se o domínio é acessível, baseado no tempo mínimo entre dois acessos e o tempo do último acesso e tempo atual \n",
    "- Scheduler:\n",
    "    - `can_add_page`: adiociona a página caso a página ainda não tenha sido adicionada no dincionário de páginas e caso a profundidade da página analisada seja menor que a profundidade limiite\n",
    "    - `add_new_page`: confere, baseado no método `can_add_page` se a página pode ser adicionada e caso possa a página será adicionada no dicionário de páginas e irá agrupar todas as urls pelo domínio\n",
    "    - `get_next_url`: tendo o dicionário das urls agrupadas por domínio, esse método irá sempre retornar a próxima página da lista, esvaziando primeiro cada agrupamento de domnínio\n",
    "    - `can_fetch_page`: irá pegar os arquivos robots.txt e cada domínio analisado e armazena esses robots em um dicionário.\n",
    "- PageFetcher\n",
    "    - `request_url`: pega o conteúdo da página. É passado o nome do coletor e é extraído o conteúdo de cada página, nesse caso é feito um filtro para pegar apenas o conteúdo HTML.\n",
    "    - `discover_links`: recebe a url da página coletada, a profundidade limite e o conteúdo em binário. Primeiro é convertido o conteúdo em binário para HTML e dentro desse conteúdo é procurado os links que estão dentro do conteúdo dessa página. Esses novos links são retornados na função junto com a nova profundidade.\n",
    "    - `crawl_new_url`: através do escalonador, é pego a nova url do dicionário, a próxima url que deve ser coletada\n",
    "    - `run`: método de teste para coletar páginas a partir de algumas sementes e irá coletar até que se chege ao limite de páginas coletadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O impacto na velocidade de coleta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foram considerados 30 sementes, com um limite de cinquenta mil páginas e com produndidade máxima de 6. Todos os casos demoraram muito sendo inviável a comprarção. As páginas coletadas podem ser encontradas no arquivo `paginas-coletadas.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link para a página descrevendo o coletor criado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://armonovabot.wordpress.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
